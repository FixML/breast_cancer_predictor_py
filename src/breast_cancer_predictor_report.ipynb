{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting breast cancer from digitized images of breast mass\n",
    "\n",
    "by Tiffany A. Timbers, Joel Ostblom & Melissa Lee\n",
    "2023/11/09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<jemalloc>: MADV_DONTNEED does not work (memset will be used instead)\n",
      "<jemalloc>: (This is the expected behaviour if you are running under QEMU)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import altair as alt\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Here we attempt to build a classification model using the k-nearest neighbours algorithm which can use breast cancer tumour image measurements to predict whether a newly discovered breast cancer tumour is benign (i.e., is not harmful and does not require treatment) or malignant (i.e., is harmful and requires treatment intervention). Our final classifier performed fairly well on an unseen test data set, with the F2 score, where beta = 2, of 0.96 and an overall accuracy calculated to be 0.96. On the 171 test data cases, it correctly predicted 168. It incorrectly predicted 3 cases, which were all false positives - predicting that a tumour is malignant when in fact it is benign. These kind of incorrect predictions is not as harmful as a false negative in our context. Although they could theoretically cause the patient to undergo unnecessary treatment if the model is used as a decision tool, it is likely that the model is used for initial screening and that there will be a follow up appointment and further testing until treatment commences. As such, we believe this model is at, or close to, the performance required for it to have clinical utility, although further research to improve the model performance and understand the characteristics of incorrectly predicted patients would still be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Women have a 12.1% lifetime probability of developing breast cancer, and although cancer treatment has improved over the last 30 years, the projected death rate for women's breast cancer is 22.4 deaths per 100,000 in 2019 (Canadian Cancer Statistics Advisory Committee 2019). Early detection has been shown to improve outcomes (Canadian Cancer Statistics Advisory Committee 2019), and thus methods, assays and technologies that help to improve diagnosis may be beneficial for improving outcomes further. \n",
    "\n",
    "Here we ask if we can use a machine learning algorithm to predict whether a newly discovered tumour is benign or malignant given tumour image measurements. Answering this question is important because traditional methods for tumour diagnosis are quite subjective and can depend on the diagnosing physicians skill as well as experience (Street, Wolberg, and Mangasarian 1993). Furthermore, benign tumours are not normally dangerous; the cells stay in the same place and the tumour stops growing before it gets very large. By contrast, in malignant tumours, the cells invade the surrounding tissue and spread into nearby organs where they can cause serious damage. Thus, if a machine learning algorithm can accurately and effectively predict whether a newly discovered tumour benign or malignant given tumour image measurements this could lead to less subjective, and more scalable breast cancer tumour diagnosis which could contribute to better patient outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "## Data\n",
    "The data set used in this project is of digitized breast cancer image features created by Dr. William H. Wolberg, W. Nick Street, and Olvi L. Mangasarian at the University of Wisconsin, Madison (Street, Wolberg, and Mangasarian 1993).  It was sourced from the UCI Machine Learning Repository (Street, Wolberg, and Mangasarian 1993) and can be found [here](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)), specifically [this file](http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data). Each row in the data set represents summary statistics from measurements of an image of a tumour sample, including the diagnosis (benign or malignant) and several other measurements (e.g., nucleus texture, perimeter, area, etc.). Diagnosis for each image was conducted by physicians. \n",
    "\n",
    "## Analysis\n",
    "The k-nearest neighbors (k-nn) algorithm was used to build a classification model to predict whether a tumour mass was benign or malignant (found in the class column of the data set). All variables included in the original data set, with the exception of the standard error of fractal dimension, smoothness, symmetry and texture were used to fit the model. Data was split with 70% being partitioned into the training set and 30% being partitioned into the test set. The hyperparameter $K$ was chosen using 30-fold cross validation with the F2 score as the classification metric. Beta was chosen to be set to 2 for the F2 score to increase the weight on recall during fitting because the application is cancer screening and false negatives are very undesirable in such an application. All variables were standardized just prior to model fitting. The Python programming language (Van Rossum and Drake 2009) and the following Python packages were used to perform the analysis: requests(Reitz 2011), zipfile (Van Rossum and Drake 2009), numpy(Harris et al. 2020), Pandas (McKinney 2010), altair (VanderPlas, 2018), scikit-learn (Pedregosa et al. 2011). The code used to perform the analysis and create this report can be found here: https://github.com/ttimbers/breast_cancer_predictor_py.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results & Discussion\n",
    "\n",
    "To look at whether each of the predictors might be useful to predict the tumour class, we plotted the distributions of each predictor from the training data set and coloured the distribution by class (benign: blue and malignant: orange). In doing this we see that class distributions for all of the mean and max predictors for all the measurements overlap somewhat, but do show quite a difference in their centres and spreads. This is less so for the standard error (se) predictors. In particular, the standard errors of fractal dimension, smoothness, symmetry and texture look very similar in both the distribution centre and spread. Thus, we choose to omit these from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data as zip and extract\n",
    "url = \"https://archive.ics.uci.edu/static/public/15/breast+cancer+wisconsin+original.zip\"\n",
    "\n",
    "request = requests.get(url)\n",
    "with open(\"../data/raw/breast+cancer+wisconsin+original.zip\", 'wb') as f:\n",
    "    f.write(request.content)\n",
    "\n",
    "with zipfile.ZipFile(\"../data/raw/breast+cancer+wisconsin+original.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"../data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>max_radius</th>\n",
       "      <th>max_texture</th>\n",
       "      <th>max_perimeter</th>\n",
       "      <th>max_area</th>\n",
       "      <th>max_smoothness</th>\n",
       "      <th>max_compactness</th>\n",
       "      <th>max_concavity</th>\n",
       "      <th>max_concave_points</th>\n",
       "      <th>max_symmetry</th>\n",
       "      <th>max_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Benign</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         class  mean_radius  mean_texture  mean_perimeter  mean_area  \\\n",
       "0    Malignant        17.99         10.38          122.80     1001.0   \n",
       "1    Malignant        20.57         17.77          132.90     1326.0   \n",
       "2    Malignant        19.69         21.25          130.00     1203.0   \n",
       "3    Malignant        11.42         20.38           77.58      386.1   \n",
       "4    Malignant        20.29         14.34          135.10     1297.0   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564  Malignant        21.56         22.39          142.00     1479.0   \n",
       "565  Malignant        20.13         28.25          131.20     1261.0   \n",
       "566  Malignant        16.60         28.08          108.30      858.1   \n",
       "567  Malignant        20.60         29.33          140.10     1265.0   \n",
       "568     Benign         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     mean_symmetry  ...  max_radius  max_texture  max_perimeter  max_area  \\\n",
       "0           0.2419  ...      25.380        17.33         184.60    2019.0   \n",
       "1           0.1812  ...      24.990        23.41         158.80    1956.0   \n",
       "2           0.2069  ...      23.570        25.53         152.50    1709.0   \n",
       "3           0.2597  ...      14.910        26.50          98.87     567.7   \n",
       "4           0.1809  ...      22.540        16.67         152.20    1575.0   \n",
       "..             ...  ...         ...          ...            ...       ...   \n",
       "564         0.1726  ...      25.450        26.40         166.10    2027.0   \n",
       "565         0.1752  ...      23.690        38.25         155.00    1731.0   \n",
       "566         0.1590  ...      18.980        34.12         126.70    1124.0   \n",
       "567         0.2397  ...      25.740        39.42         184.60    1821.0   \n",
       "568         0.1587  ...       9.456        30.37          59.16     268.6   \n",
       "\n",
       "     max_smoothness  max_compactness  max_concavity  max_concave_points  \\\n",
       "0           0.16220          0.66560         0.7119              0.2654   \n",
       "1           0.12380          0.18660         0.2416              0.1860   \n",
       "2           0.14440          0.42450         0.4504              0.2430   \n",
       "3           0.20980          0.86630         0.6869              0.2575   \n",
       "4           0.13740          0.20500         0.4000              0.1625   \n",
       "..              ...              ...            ...                 ...   \n",
       "564         0.14100          0.21130         0.4107              0.2216   \n",
       "565         0.11660          0.19220         0.3215              0.1628   \n",
       "566         0.11390          0.30940         0.3403              0.1418   \n",
       "567         0.16500          0.86810         0.9387              0.2650   \n",
       "568         0.08996          0.06444         0.0000              0.0000   \n",
       "\n",
       "     max_symmetry  max_fractal_dimension  \n",
       "0          0.4601                0.11890  \n",
       "1          0.2750                0.08902  \n",
       "2          0.3613                0.08758  \n",
       "3          0.6638                0.17300  \n",
       "4          0.2364                0.07678  \n",
       "..            ...                    ...  \n",
       "564        0.2060                0.07115  \n",
       "565        0.2572                0.06637  \n",
       "566        0.2218                0.07820  \n",
       "567        0.4087                0.12400  \n",
       "568        0.2871                0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-process data (e.g., scale and split into train & test)\n",
    "# read in data\n",
    "colnames = [\n",
    "    \"id\",\n",
    "    \"class\",\n",
    "    \"mean_radius\",\n",
    "    \"mean_texture\",\n",
    "    \"mean_perimeter\", \n",
    "    \"mean_area\",\n",
    "    \"mean_smoothness\",\n",
    "    \"mean_compactness\",\n",
    "    \"mean_concavity\",\n",
    "    \"mean_concave_points\",\n",
    "    \"mean_symmetry\",\n",
    "    \"mean_fractal_dimension\",\n",
    "    \"se_radius\",\n",
    "    \"se_texture\",\n",
    "    \"se_perimeter\", \n",
    "    \"se_area\",\n",
    "    \"se_smoothness\",\n",
    "    \"se_compactness\",\n",
    "    \"se_concavity\",\n",
    "    \"se_concave_points\",\n",
    "    \"se_symmetry\",\n",
    "    \"se_fractal_dimension\",\n",
    "    \"max_radius\",\n",
    "    \"max_texture\",\n",
    "    \"max_perimeter\", \n",
    "    \"max_area\",\n",
    "    \"max_smoothness\",\n",
    "    \"max_compactness\",\n",
    "    \"max_concavity\",\n",
    "    \"max_concave_points\",\n",
    "    \"max_symmetry\",\n",
    "    \"max_fractal_dimension\"\n",
    "]\n",
    "\n",
    "cancer = pd.read_csv(\"../data/raw/wdbc.data\", names=colnames, header=None).drop(columns=['id'])\n",
    "# re-label Class 'M' as 'Malignant', and Class 'B' as 'Benign'\n",
    "cancer['class'] = cancer['class'].replace({\n",
    "    'M' : 'Malignant',\n",
    "    'B' : 'Benign'\n",
    "})\n",
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(522)\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# create the split\n",
    "cancer_train, cancer_test = train_test_split(\n",
    "    cancer, train_size=0.70, stratify=cancer[\"class\"]\n",
    ")\n",
    "\n",
    "cancer_train.to_csv(\"../data/processed/cancer_train.csv\")\n",
    "cancer_test.to_csv(\"../data/processed/cancer_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), make_column_selector(dtype_include='number')),\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "cancer_preprocessor.fit(cancer_train)\n",
    "scaled_cancer_train = cancer_preprocessor.transform(cancer_train)\n",
    "scaled_cancer_test = cancer_preprocessor.transform(cancer_test)\n",
    "\n",
    "scaled_cancer_train.to_csv(\"../data/processed/scaled_cancer_train.csv\")\n",
    "scaled_cancer_test.to_csv(\"../data/processed/scaled_cancer_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt for plotting via facets \n",
    "cancer_train_melted = scaled_cancer_train.melt(\n",
    "    id_vars=['class'],\n",
    "    var_name='predictor',\n",
    "    value_name='value'\n",
    ")\n",
    "\n",
    "# make columns names nicer for plotting\n",
    "cancer_train_melted['predictor'] = cancer_train_melted['predictor'].str.replace('_',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploratory data analysis - visualize predictor distributions across classes\n",
    "alt.data_transformers.enable('vegafusion')\n",
    "\n",
    "alt.Chart(cancer_train_melted, width=150, height=100).transform_density(\n",
    "    'value',\n",
    "    groupby=['class', 'predictor']\n",
    ").mark_area(opacity=0.7).encode(\n",
    "    x=\"value:Q\",\n",
    "    y=alt.Y('density:Q').stack(False),\n",
    "    color='class:N'\n",
    ").facet(\n",
    "    'predictor:N',\n",
    "    columns=5\n",
    ").resolve_scale(\n",
    "    y='independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1. Comparison of the empirical distributions of training data predictors between benign and malignant tumour masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop se_smoothness, se_symmetry, se_texture\n",
    "cancer_train = cancer_train.drop(columns=[\"se_smoothness\", \"se_symmetry\", \"se_texture\", \"se_fractal_dimension\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use a simple classification model using the k-nearest neighbours algorithm. To find the model that best predicted whether a tumour was benign or malignant, we performed 30-fold cross validation using F2 score (beta = 2) as our metric of model prediction performance to select K (number of nearest neighbours). We observed that the optimal K was 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune model (here, find K for k-nn using 30 fold cv)\n",
    "knn = KNeighborsClassifier()\n",
    "cancer_tune_pipe = make_pipeline(cancer_preprocessor, knn)\n",
    "\n",
    "parameter_grid = {\n",
    "    \"kneighborsclassifier__n_neighbors\": range(1, 100, 3),\n",
    "}\n",
    "\n",
    "cv = 30\n",
    "cancer_tune_grid = GridSearchCV(\n",
    "    estimator=cancer_tune_pipe,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cv,\n",
    "    scoring=make_scorer(fbeta_score, pos_label='Malignant', beta=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_fit = cancer_tune_grid.fit(\n",
    "    cancer_train.drop(columns=[\"class\"]),\n",
    "    cancer_train[\"class\"]\n",
    ")\n",
    "\n",
    "accuracies_grid = pd.DataFrame(cancer_fit.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_grid = (\n",
    "    accuracies_grid[[\n",
    "        \"param_kneighborsclassifier__n_neighbors\",\n",
    "        \"mean_test_score\",\n",
    "        \"std_test_score\"\n",
    "    ]]\n",
    "    .assign(\n",
    "        sem_test_score=accuracies_grid[\"std_test_score\"] / cv**(1/2),\n",
    "        # `lambda` allows access to the chained dataframe so that we can use the newly created `sem_test_score` column \n",
    "        sem_test_score_lower=lambda df: df[\"mean_test_score\"] - (df[\"sem_test_score\"]/2),\n",
    "        sem_test_score_upper=lambda df: df[\"mean_test_score\"] + (df[\"sem_test_score\"]/2)\n",
    "    )\n",
    "    .rename(columns={\"param_kneighborsclassifier__n_neighbors\": \"n_neighbors\"})\n",
    "    .drop(columns=[\"std_test_score\"])\n",
    ")\n",
    "\n",
    "accuracies_grid.sort_values(\"mean_test_score\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_n_point = alt.Chart(accuracies_grid, width=600).mark_line(color=\"black\").encode(\n",
    "    x=alt.X(\"n_neighbors\").title(\"Neighbors\"),\n",
    "    y=alt.Y(\"mean_test_score\")\n",
    "        .scale(zero=False) \n",
    "        .title(\"F2 score (beta = 2)\")\n",
    ")\n",
    "\n",
    "error_bar = alt.Chart(accuracies_grid).mark_errorbar().encode(\n",
    "    alt.Y(\"sem_test_score_upper:Q\").scale(zero=False).title(\"F2 score (beta = 2)\"),\n",
    "    alt.Y2(\"sem_test_score_lower:Q\"),\n",
    "    alt.X(\"n_neighbors:Q\").title(\"Neighbors\")\n",
    ")\n",
    "\n",
    "line_n_point + line_n_point.mark_circle(color='black') + error_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2. Results from 30-fold cross validation to choose K. F2 score (with beta = 2) was used as the classification metric as K was varied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy\n",
    "accuracy = cancer_fit.score(\n",
    "    cancer_test.drop(columns=[\"class\"]),\n",
    "    cancer_test[\"class\"]\n",
    ")\n",
    "\n",
    "# Compute F2 score (beta = 2)\n",
    "cancer_preds = cancer_test.assign(\n",
    "    predicted=cancer_fit.predict(cancer_test)\n",
    ")\n",
    "f2_beta_2_score = fbeta_score(\n",
    "    cancer_preds['class'],\n",
    "    cancer_preds['predicted'],\n",
    "    beta=2,\n",
    "    pos_label='Malignant'\n",
    ")\n",
    "\n",
    "pd.DataFrame({'accuracy': [accuracy], 'F2 score (beta = 2)': [f2_beta_2_score]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prediction model performed quite well on test data, with a final overall accuracy of 0.96 and F2 (beta = 2) score of 0.98. Other indicators that our model performed well come from the confusion matrix, where it only made 3 mistakes. All 3 mistakes were predicting a benign tumour as malignant, which is promising for implementing this in the clinic as false positives are less harmful than false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1. Confusion matrix of model performance on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    cancer_preds[\"class\"],\n",
    "    cancer_preds[\"predicted\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the performance of this model is likely already useful as a screening tool in a clinical setting, there are several directions that could be explored for to improve it further. First, we could look closely at the 3 misclassified observations and compare them to several observations that were classified correctly (from both classes). The goal of this would be to see which feature(s) may be driving the misclassification and explore whether any feature engineering could be used to help the model better predict on observations that it currently is making mistakes on. Additionally, we would try seeing whether we can get improved predictions using other classifiers. One classifier we might try is random forest forest because it automatically allows for feature interaction, where k-nn does not. Finally, we also might improve the usability of the model in the clinic if we output and report the probability estimates for predictions. If we cannot prevent misclassifications through the approaches suggested above, at least reporting a probability estimates for predictions would allow the clinician to know how confident the model was in its prediction. Thus the clinician may then have the ability to perform additional diagnostic assays if the probability estimates for prediction of a given tumour class is not very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Canadian Cancer Statistics Advisory Committee. 2019. “Canadian Cancer Statistics.” Canadian Cancer Society. http://cancer.ca/Canadian-Cancer-Statistics-2019-EN.\n",
    "\n",
    "Dua, Dheeru, and Casey Graff. 2017. “UCI Machine Learning Repository.” University of California, Irvine, School of Information; Computer Sciences. http://archive.ics.uci.edu/ml.\n",
    "\n",
    "Harris, C.R. et al., 2020. Array programming with NumPy. Nature, 585, pp.357–362.\n",
    "\n",
    "Jed Wing, Max Kuhn. Contributions from, Steve Weston, Andre Williams, Chris Keefer, Allan Engelhardt, Tony Cooper, Zachary Mayer, et al. 2019. Caret: Classification and Regression Training. https://CRAN.R-project.org/package=caret.\n",
    "\n",
    "McKinney, Wes. 2010. “Data Structures for Statistical Computing in Python.” In Proceedings of the 9th Python in Science Conference, edited by Stéfan van der Walt and Jarrod Millman, 51–56.\n",
    "\n",
    "Pedregosa, F. et al., 2011. Scikit-learn: Machine learning in Python. Journal of machine learning research, 12(Oct), pp.2825–2830.\n",
    "\n",
    "Reitz, Kenneth. 2011. Requests: HTTP for Humans. https://requests.readthedocs.io/en/master/.\n",
    "\n",
    "Street, W. Nick, W. H. Wolberg, and O. L. Mangasarian. 1993. “Nuclear feature extraction for breast tumor diagnosis.” In Biomedical Image Processing and Biomedical Visualization, edited by Raj S. Acharya and Dmitry B. Goldgof, 1905:861–70. International Society for Optics; Photonics; SPIE. https://doi.org/10.1117/12.148698.\n",
    "\n",
    "VanderPlas, J. et al., 2018. Altair: Interactive statistical visualizations for python. Journal of open source software, 3(32), p.1057.\n",
    "\n",
    "Van Rossum, Guido, and Fred L. Drake. 2009. Python 3 Reference Manual. Scotts Valley, CA: CreateSpace.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
